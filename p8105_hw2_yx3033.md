p8105_hw2_yx3033
================

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(dplyr)
library(readxl)
library(lubridate)
```

## Problem 1

Clean pols data set

``` r
pols_df = 
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon,into=c("year","month","day")) |> 
  mutate(
    year=as.integer(year),
    month = as.integer(month),
    day = as.integer(day)
  ) |> 
  mutate(month=month.name[month]) |> 
  mutate(president=if_else(prez_gop==1,"gop","dem")) |> 
  select(-prez_dem,-prez_gop,-day)
pols_df
```

    ## # A tibble: 822 × 9
    ##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <int> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 January        23      51     253      23      45     198 dem      
    ##  2  1947 February       23      51     253      23      45     198 dem      
    ##  3  1947 March          23      51     253      23      45     198 dem      
    ##  4  1947 April          23      51     253      23      45     198 dem      
    ##  5  1947 May            23      51     253      23      45     198 dem      
    ##  6  1947 June           23      51     253      23      45     198 dem      
    ##  7  1947 July           23      51     253      23      45     198 dem      
    ##  8  1947 August         23      51     253      23      45     198 dem      
    ##  9  1947 September      23      51     253      23      45     198 dem      
    ## 10  1947 October        23      51     253      23      45     198 dem      
    ## # ℹ 812 more rows

clean snv dataset

``` r
snv_df =
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date,into=c("month","day","year"), sep="/") |> 
  mutate(
    year = as.integer(if_else(as.integer(year) > 15, paste0("19", year), paste0("20", year))),
    month = as.integer(month),
    day = as.integer(day)
  ) |> 
  mutate(month = month.name[month]) |> 
  select(year, month, close) |> 
  arrange(year, match(month, month.name))
snv_df
```

    ## # A tibble: 787 × 3
    ##     year month     close
    ##    <int> <chr>     <dbl>
    ##  1  1950 January    17.0
    ##  2  1950 February   17.2
    ##  3  1950 March      17.3
    ##  4  1950 April      18.0
    ##  5  1950 May        18.8
    ##  6  1950 June       17.7
    ##  7  1950 July       17.8
    ##  8  1950 August     18.4
    ##  9  1950 September  19.5
    ## 10  1950 October    19.5
    ## # ℹ 777 more rows

clean unemployment data set

``` r
unemp_df =
  read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) |> 
  mutate(
    month = month.name[match(tolower(month), tolower(month.abb))]
  ) |> 
  select(year, month, unemployment)
unemp_df
```

    ## # A tibble: 816 × 3
    ##     year month     unemployment
    ##    <dbl> <chr>            <dbl>
    ##  1  1948 January            3.4
    ##  2  1948 February           3.8
    ##  3  1948 March              4  
    ##  4  1948 April              3.9
    ##  5  1948 May                3.5
    ##  6  1948 June               3.6
    ##  7  1948 July               3.6
    ##  8  1948 August             3.9
    ##  9  1948 September          3.8
    ## 10  1948 October            3.7
    ## # ℹ 806 more rows

join snv into pols and merge in unemployment

``` r
merged_df =
  left_join(pols_df,snv_df, by = c("year", "month")) |> 
  left_join(unemp_df, by = c("year", "month"))
merged_df
```

    ## # A tibble: 822 × 11
    ##     year month   gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1  1947 January      23      51     253      23      45     198 dem          NA
    ##  2  1947 Februa…      23      51     253      23      45     198 dem          NA
    ##  3  1947 March        23      51     253      23      45     198 dem          NA
    ##  4  1947 April        23      51     253      23      45     198 dem          NA
    ##  5  1947 May          23      51     253      23      45     198 dem          NA
    ##  6  1947 June         23      51     253      23      45     198 dem          NA
    ##  7  1947 July         23      51     253      23      45     198 dem          NA
    ##  8  1947 August       23      51     253      23      45     198 dem          NA
    ##  9  1947 Septem…      23      51     253      23      45     198 dem          NA
    ## 10  1947 October      23      51     253      23      45     198 dem          NA
    ## # ℹ 812 more rows
    ## # ℹ 1 more variable: unemployment <dbl>

Description:  
The merged dataset combines three original FiveThirtyEight datasets:
`pols-month`, `snp`, and `unemployment`. The `pols-month` dataset
contains information on the number of Republican and Democratic
politicians, including presidents, governors, senators, and
representatives, with 822 monthly observations from 1947 onward. The
`snp` dataset contains monthly closing values of the Standard & Poor’s
(S&P) 500 index, with 787 observations. The `unemployment` dataset
records monthly unemployment rates by year, originally in a wide format
with one row per year and separate columns for each month. After tidying
and merging, the resulting dataset has 822 rows and 11 key variables:
`year`, `month`, `gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`,
`rep_dem`, `president`, `close` (S&P 500), and `unemployment`. The
dataset spans from 1947 through 2015, with consistent month names, which
enables analyses that relate to political composition, economic
indicators, and labor market conditions over time.

## Problem 2

``` r
mr_trash =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             skip =1) |> 
  janitor::clean_names() |> 
  select(where(~!all(is.na(.)))) |>
  filter(!is.na(dumpster)) |> 
  mutate(year = as.integer(year),
         sports_balls = as.integer(round(sports_balls)),
         trash_wheel = "Mr. Trash Wheel")
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
mr_trash
```

    ## # A tibble: 707 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <int> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 697 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, trash_wheel <chr>

``` r
pro_trash = 
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel",
             skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(trash_wheel = "Professor Trash Wheel")

gwyn_trash = 
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynns Falls Trash Wheel",
             skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(trash_wheel = "Gwynnda")
```

combine all three:

``` r
all_trash <- bind_rows(mr_trash, pro_trash, gwyn_trash) |> 
  mutate(cigarette_butts = as.integer(round(cigarette_butts)))
```

The trash collection dataset combines records from multiple trash
wheels, including Mr. Trash Wheel, Professor Trash Wheel, and Gwynns
Falls Trash Wheel spanning from 2014 to 2025. The resulting dataset
contains 707 observations and 15 variables, such as `dumpster` (the
dumpster ID), `weight_tons` (weight of trash collected),
`cigarette_butts`, `plastic_bottles`, `sports_balls`,
`volume_cubic_yards`, `homes_powered` and `trash_wheel` indicating which
trash wheel sites is that line of data from. These variables provide
types and quantities of waste collected on each date and sites. For
example, the total weight of trash collected by Professor Trash Wheel
was 282.26 tons. The total number of cigarette butts collected by
Gwynnda in June of 2022 was 18120. This dataset allows for detailed
exploration of waste composition across different trash wheels and at
different time periods.

## Problem 3

``` r
zip_codes=
  read_csv("data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  mutate(zip_code = as.character(zip_code))
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

deleated ‘county’ after county Bronx

``` r
zip_zori =
  read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  janitor::clean_names() |> 
  mutate(
    county_name = str_remove_all(county_name,"County"),
    county_name = trimws(county_name),
    region_name = as.character(region_name),
  ) |> 
  rename_with(~ str_remove(.x, "^x"))
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

check for duplicates in the zip_codes dataset

``` r
zip_codes_dupes = zip_codes |> 
  group_by(zip_code)  |> 
  filter(n() > 1)  |> 
  ungroup()
zip_codes_dupes
```

    ## # A tibble: 4 × 7
    ##   county   state_fips county_code county_fips zip_code file_date neighborhood   
    ##   <chr>         <dbl> <chr>             <dbl> <chr>    <chr>     <chr>          
    ## 1 Bronx            36 005               36005 10463    7/25/07   Kingsbridge an…
    ## 2 Kings            36 047               36047 11201    7/25/07   Northwest Broo…
    ## 3 New York         36 061               36061 10463    7/25/07   Kingsbridge an…
    ## 4 New York         36 061               36061 11201    7/25/07   Northwest Broo…

``` r
zip_zori_dupes = zip_zori |> 
  group_by(region_name)  |> 
  filter(n() > 1)  |> 
  ungroup()
zip_zori_dupes
```

    ## # A tibble: 0 × 125
    ## # ℹ 125 variables: region_id <dbl>, size_rank <dbl>, region_name <chr>,
    ## #   region_type <chr>, state_name <chr>, state <chr>, city <chr>, metro <chr>,
    ## #   county_name <chr>, 2015_01_31 <dbl>, 2015_02_28 <dbl>, 2015_03_31 <dbl>,
    ## #   2015_04_30 <dbl>, 2015_05_31 <dbl>, 2015_06_30 <dbl>, 2015_07_31 <dbl>,
    ## #   2015_08_31 <dbl>, 2015_09_30 <dbl>, 2015_10_31 <dbl>, 2015_11_30 <dbl>,
    ## #   2015_12_31 <dbl>, 2016_01_31 <dbl>, 2016_02_29 <dbl>, 2016_03_31 <dbl>,
    ## #   2016_04_30 <dbl>, 2016_05_31 <dbl>, 2016_06_30 <dbl>, 2016_07_31 <dbl>, …

``` r
cat("Duplicate zip codes found:", nrow(zip_codes_dupes), "\n")
```

    ## Duplicate zip codes found: 4

``` r
cat("Duplicate region_names found:", nrow(zip_zori_dupes), "\n")
```

    ## Duplicate region_names found: 0

``` r
#ZIP 10463 appears in both Bronx County and New York County (Manhattan)
#ZIP 11201 appears in both Kings County (Brooklyn) and New York County (Manhattan)
```

``` r
zori_tidy = zip_zori |> 
  pivot_longer(
    cols = `2015_01_31`:`2024_08_31`,
    names_to = "date",
    values_to = "rent_index") |>
  mutate(date = lubridate::ymd(date)) |> 
  filter(!is.na(rent_index)) |> 
  select(-region_type,-state_name
  )
```

merge two

``` r
final_dataset = zori_tidy |> 
  left_join(
    zip_codes, 
    by = c("region_name" = "zip_code", "county_name" = "county")
  )
```

arrange by importance

``` r
final_dataset = final_dataset  |> 
  
  mutate(zip_code = region_name,
         borough = county_name) |> 
  select(
    zip_code, 
    borough, 
    neighborhood, date, rent_index,
    city, metro, state, size_rank, 
    everything()
  ) |> 
  arrange(borough, neighborhood, date)
```

total observation, unique zip and neighborhoods

``` r
total_obs <- nrow(final_dataset)
cat("Total observations:", total_obs, "\n")
```

    ## Total observations: 10450

``` r
unique_zips <- n_distinct(final_dataset$zip_code)
cat("Unique ZIP codes:", unique_zips, "\n")
```

    ## Unique ZIP codes: 149

``` r
unique_neighborhoods <- n_distinct(final_dataset$neighborhood)
cat("Unique neighborhoods:", unique_neighborhoods, "\n")
```

    ## Unique neighborhoods: 43
