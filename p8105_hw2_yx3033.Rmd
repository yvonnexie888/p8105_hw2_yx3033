---
title: "p8105_hw2_yx3033"
Author: "Yvonne Xie"
Data: "2025-10-01"
output: github_document
---

```{r}
library(tidyverse)
library(dplyr)
library(readxl)
library(lubridate)
```

## Problem 1
Clean pols data set

```{r message=FALSE, warning=FALSE}
pols_df = 
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon,into=c("year","month","day")) |> 
  mutate(
    year=as.integer(year),
    month = as.integer(month),
    day = as.integer(day)
  ) |> 
  mutate(month=month.name[month]) |> 
  mutate(president=if_else(prez_gop==1,"gop","dem")) |> 
  select(-prez_dem,-prez_gop,-day)
pols_df
```

clean snv dataset

```{r message=FALSE, warning=FALSE}
snv_df =
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date,into=c("month","day","year"), sep="/") |> 
  mutate(
    year = as.integer(if_else(as.integer(year) > 15, paste0("19", year), paste0("20", year))),
    month = as.integer(month),
    day = as.integer(day)
  ) |> 
  mutate(month = month.name[month]) |> 
  select(year, month, close) |> 
  arrange(year, match(month, month.name))
snv_df
```

clean unemployment data set
```{r message=FALSE, warning=FALSE}
unemp_df =
  read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) |> 
  mutate(
    month = month.name[match(tolower(month), tolower(month.abb))]
  ) |> 
  select(year, month, unemployment)
unemp_df
```

join snv into pols and merge in unemployment

```{r}
merged_df =
  left_join(pols_df,snv_df, by = c("year", "month")) |> 
  left_join(unemp_df, by = c("year", "month"))
merged_df
```

Description:  
The merged dataset combines three original FiveThirtyEight datasets: `pols-month`, `snp`, and `unemployment`. The `pols-month` dataset contains information on the number of Republican and Democratic politicians, including presidents, governors, senators, and representatives, with 822 monthly observations from 1947 onward. The `snp` dataset contains monthly closing values of the Standard & Poorâ€™s (S&P) 500 index, with 787 observations. The `unemployment` dataset records monthly unemployment rates by year, originally in a wide format with one row per year and separate columns for each month. After tidying and merging, the resulting dataset has 822 rows and 11 key variables: `year`, `month`, `gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem`, `president`, `close` (S&P 500), and `unemployment`. The dataset spans from 1947 through 2015, with consistent month names, which enables analyses that relate to political composition, economic indicators, and labor market conditions over time.  


## Problem 2

```{r}
mr_trash =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             skip =1) |> 
  janitor::clean_names() |> 
  select(where(~!all(is.na(.)))) |>
  filter(!is.na(dumpster)) |> 
  mutate(year = as.integer(year),
         sports_balls = as.integer(round(sports_balls)),
         trash_wheel = "Mr. Trash Wheel")

mr_trash
```


```{r}
pro_trash = 
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel",
             skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(trash_wheel = "Professor Trash Wheel")

gwyn_trash = 
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynns Falls Trash Wheel",
             skip = 1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(trash_wheel = "Gwynnda")
```

combine all three:
```{r}
all_trash <- bind_rows(mr_trash, pro_trash, gwyn_trash) |> 
  mutate(cigarette_butts = as.integer(round(cigarette_butts)))
```

The trash collection dataset combines records from multiple trash wheels, including Mr. Trash Wheel, Professor Trash Wheel, and Gwynns Falls Trash Wheel spanning from 2014 to 2025. The resulting dataset contains `r nrow(mr_trash)` observations and 15 variables, such as `dumpster` (the dumpster ID), `weight_tons` (weight of trash collected), `cigarette_butts`, `plastic_bottles`, `sports_balls`, `volume_cubic_yards`, `homes_powered` and `trash_wheel` indicating which trash wheel sites is that line of data from. These variables provide types and quantities of waste collected on each date and sites. For example, the total weight of trash collected by Professor Trash Wheel was `r sum(all_trash$weight_tons[all_trash$trash_wheel == "Professor Trash Wheel"], na.rm = TRUE)` tons. The total number of cigarette butts collected by Gwynnda in June of 2022 was `r sum(all_trash$cigarette_butts[all_trash$trash_wheel == "Gwynnda" & all_trash$month == "June" & all_trash$year == 2022], na.rm = TRUE)`. This dataset allows for detailed exploration of waste composition across different trash wheels and at different time periods.


## Problem 3

```{r}
zip_codes=
  read_csv("data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  mutate(zip_code = as.character(zip_code))
```

deleated 'county' after county Bronx
```{r}
zip_zori =
  read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  janitor::clean_names() |> 
  mutate(
    county_name = str_remove_all(county_name,"County"),
    county_name = trimws(county_name),
    region_name = as.character(region_name),
  ) |> 
  rename_with(~ str_remove(.x, "^x"))
```

check for duplicates in the zip_codes dataset
```{r}
zip_codes_dupes = zip_codes |> 
  group_by(zip_code)  |> 
  filter(n() > 1)  |> 
  ungroup()
zip_codes_dupes

zip_zori_dupes = zip_zori |> 
  group_by(region_name)  |> 
  filter(n() > 1)  |> 
  ungroup()
zip_zori_dupes

cat("Duplicate zip codes found:", nrow(zip_codes_dupes), "\n")
cat("Duplicate region_names found:", nrow(zip_zori_dupes), "\n")

#ZIP 10463 appears in both Bronx County and New York County (Manhattan)
#ZIP 11201 appears in both Kings County (Brooklyn) and New York County (Manhattan)
```


```{r}

zori_tidy = zip_zori |> 
  pivot_longer(
    cols = `2015_01_31`:`2024_08_31`,
    names_to = "date",
    values_to = "rent_index") |>
  mutate(date = lubridate::ymd(date)) |> 
  filter(!is.na(rent_index)) |> 
  select(-region_type,-state_name
  )
```

merge two
```{r}
final_dataset = zori_tidy |> 
  left_join(
    zip_codes, 
    by = c("region_name" = "zip_code", "county_name" = "county")
  )
```
arrange by importance
```{r}
final_dataset = final_dataset  |> 
  
  mutate(zip_code = region_name,
         borough = county_name) |> 
  select(
    zip_code, 
    borough, 
    neighborhood, date, rent_index,
    city, metro, state, size_rank, 
    everything()
  ) |> 
  arrange(borough, neighborhood, date)

```

total observation, unique zip and neighborhoods
```{r}
total_obs <- nrow(final_dataset)
cat("Total observations:", total_obs, "\n")

unique_zips <- n_distinct(final_dataset$zip_code)
cat("Unique ZIP codes:", unique_zips, "\n")

unique_neighborhoods <- n_distinct(final_dataset$neighborhood)
cat("Unique neighborhoods:", unique_neighborhoods, "\n")
```

